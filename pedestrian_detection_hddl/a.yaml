version: '2'
services:
  test_one_model22: 
    command: /bin/bash -c "source /opt/intel/openvino/bin/setupvars.sh && /ie-serving-py/start_server.sh ie_serving model --model_path /opt/ml/pedestrian_detection_hddl --model_name pedestrian_detection_hddl --port 9001 --rest_port 8001"
    image: 'ccr.ccs.tencentyun.com/aiot-test/pedestrian_detection_hddl:latest'
    container_name: test_one_model22
    volumes:
      - /var/tmp:/var/tmp
      - /dev:/dev
    devices:
      - /dev/ion:/dev/ion
    labels:
      com_mwp_conf_nginx: '[]'
      com_mwp_conf_services: '{"function_ids":[],"google_function":false,"pub_sub":false,"mDNS":false,"secretList":[],"secret":false,"configList":[],"config":false}'
      com_mwp_conf_storage: '{"usb":false}'
    ports:
      - '8001:8001'
      - '9100:9000'
    stdin_open: true
    tty: true
    privileged: true
    environment:
      - LD_LIBRARY_PATH=/opt/intel/openvino_2019.2.242/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.2.242/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.2.242/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.2.242/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.2.242/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.2.242/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.2.242/openvx/lib
      - PYTHONPATH=/opt/intel/openvino_2019.2.242/python/python3.6:/opt/intel/openvino_2019.2.242/python/python3:/opt/intel/openvino_2019.2.242/deployment_tools/model_optimizer:/faceid_deploy
      - DEVICE=HDDL
      - CPU_EXTENSION=/libcpu_extension_sse4.so
    network_mode: host
      
